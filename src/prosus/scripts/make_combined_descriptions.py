import csv
import json
import asyncio
from pathlib import Path
from typing import Dict, Optional
import sys
from paths_ import data_dir, fivek_items_csv_path, combined_descriptions_dir

from prosus.llm_api_wrapper import ( 
    get_openai_llm_response, get_openai_vision_response, OpenAIModel
)
from prosus.utils.get_image import download_image


async def create_combined_description_for_item(
    name: str,
    description: str,
    images: list[str],
    item_id: str,
) -> str:
    """
    Create a combined, rich description for a food item using LLM.

    Args:
        name: Item name
        description: Item description
        images: List of image strings (iFood image paths)
        item_id: Unique item identifier (for logging)

    Returns:
        Combined description string generated by LLM
    """
    # Create the prompt for the LLM
    prompt = f"""
    You will be given some images of an item and its current name and description.
    Create a description for this food item that will be used in a semantic search enginer for food queries.
    Do not make this sound like an advertisement. It needs to be a backend-only description that helps match search queries to food items.

    Item Name: {name}
    Current Description: {description}

    Create a combined description that:
    1. Maintains accuracy to the original information
    2. Does not add any new information not present in the name/description/images
    3. Keywords are important for search matching, try to use them
    4. Is concise but informative (2-4 sentences)
    5. Is written in Portuguese (the same language as the input)

    Only return the combined description, nothing else.
    """

    try:
        # If images are available, download up to 5 images and use vision API
        if images and len(images) > 0:
            # Cap at 5 images for safety
            images_to_download = images[:5]
            print(f"Processing item {item_id} with {len(images_to_download)} image(s)...")

            # Download all images (up to 5)
            downloaded_image_paths = []
            for img_url in images_to_download:
                image_path = download_image(img_url)
                if image_path and Path(image_path).exists():
                    downloaded_image_paths.append(image_path)

            if downloaded_image_paths:
                # Use vision API with all downloaded images
                combined_description = await get_openai_vision_response(
                    image_inputs=downloaded_image_paths,
                    text_prompt=prompt,
                    model=OpenAIModel.GPT_5_MINI
                )
            else:
                # Fallback to text-only if all image downloads failed
                print(f"All image downloads failed for {item_id}, using text-only LLM")
                combined_description = await get_openai_llm_response(prompt)
        else:
            # No images, use text-only LLM
            print(f"Processing item {item_id} without images...")
            combined_description = await get_openai_llm_response(prompt)

        return combined_description.strip()

    except Exception as e:
        print(f"Error creating combined description for item {item_id}: {e}")
        # Fallback: return original description if LLM fails
        return description


async def make_combined_descriptions(
    input_csv_path: Optional[str],
    output_json_path: Optional[str],
    batch_size: int = 10,
    max_items: int | None = None
) -> Dict[str, str]:
    """
    Read the original CSV file and create combined descriptions using LLM.

    This function processes food items from the CSV, extracts name, description,
    and images, then queries an LLM (with vision capabilities when images are available)
    to create rich, combined descriptions.

    Args:
        input_csv_path: Path to input CSV file (default: data/5k_items_curated.csv)
        output_json_path: Path to save combined descriptions (default: data/combined_descriptions.json)
        batch_size: Number of items to process concurrently (default: 10)
        max_items: Maximum number of items to process (None = all items)

    Returns:
        Dictionary mapping item_id to combined_description
    """

    # Verify input file exists
    if not Path(input_csv_path).exists():
        raise FileNotFoundError(f"Input CSV file not found: {input_csv_path}")

    print(f"Reading CSV file: {input_csv_path}")
    print(f"Output will be saved to: {output_json_path}")

    # Dictionary to store results
    combined_descriptions = {}
    items_to_process = []

    # Read CSV file and extract items
    with open(input_csv_path, 'r', encoding='utf-8') as csv_file:
        csv_reader = csv.DictReader(csv_file)

        for row in csv_reader:
            try:
                # Parse itemMetadata JSON
                item_metadata = json.loads(row['itemMetadata'])

                # Extract required fields
                item_id = row['itemId']
                name = item_metadata.get('name', '')
                description = item_metadata.get('description', '')
                images = item_metadata.get('images', [])

                items_to_process.append({
                    'item_id': item_id,
                    'name': name,
                    'description': description,
                    'images': images
                })

                # Stop if we've reached max_items
                if max_items and len(items_to_process) >= max_items:
                    break

            except Exception as e:
                print(f"Error parsing row: {e}")
                continue

    print(f"\nProcessing {len(items_to_process)} items...")

    # Process items in batches to avoid overwhelming the API
    for i in range(0, len(items_to_process), batch_size):
        batch = items_to_process[i:i + batch_size]
        print(f"\nProcessing batch {i//batch_size + 1}/{(len(items_to_process) + batch_size - 1)//batch_size}")

        # Create tasks for concurrent processing
        tasks = [
            create_combined_description_for_item(
                name=item['name'],
                description=item['description'],
                images=item['images'],
                item_id=item['item_id']
            )
            for item in batch
        ]

        # Execute batch concurrently
        results = await asyncio.gather(*tasks)

        # Store results
        for item, combined_desc in zip(batch, results):
            combined_descriptions[item['item_id']] = combined_desc

        print(f"Completed {min(i + batch_size, len(items_to_process))}/{len(items_to_process)} items")

    # Save results to JSON file
    print(f"\nSaving combined descriptions to {output_json_path}")
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(combined_descriptions, f, ensure_ascii=False, indent=2)

    print(f"âœ“ Successfully created {len(combined_descriptions)} combined descriptions")

    return combined_descriptions


def overwrite_combined_description_field_in_jsonl():
    # read the jsonl file
    # for each item, overwrite the combined description field with the new one
    pass



#! ---- RUNNING THE METHODS ----
from datetime import datetime
async def run_make_combined_descriptions():
    input_csv = fivek_items_csv_path
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_json = Path(combined_descriptions_dir) / f"combined_descriptions_{current_time}.json"
    await make_combined_descriptions(input_csv_path=input_csv, output_json_path=str(output_json), max_items=10)
    
if __name__ == "__main__":
    asyncio.run(run_make_combined_descriptions())